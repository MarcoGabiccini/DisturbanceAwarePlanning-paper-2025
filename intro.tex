\section{Introduction}
\label{sec:intro}

As the automotive industry advances towards higher levels of automation, ...

\subsection{Related work}
In recent years, comprehensive analyses have been conducted on minimum-lap-time optimization for motorsport vehicles, covering fixed- and free-trajectory formulations~\cite{Veneri:FreetrajectoryQuasisteadystateOptimalcontrol:2020, Lovato:ThreedimensionalFixedtrajectoryApproaches:2022, Lovato:ThreedimensionalFreetrajectoryQuasisteadystate:2022}, comparing direct and indirect solution techniques~\cite{DalBianco:ComparisonDirectIndirect:2019, Bertolazzi:DirectIndirectApproach:2025}, and contrasting serial and parallel solver frameworks~\cite{Biniewicz:QuasisteadystateMinimumLap:2024, Bartali:SchwarzDecompositionParallel:2024, Bartali:ConsensusbasedAlternatingDirection:2024}.

Despite these advances, most planning frameworks still fail to incorporate robustness in the planning phase itself. Piccinini et al.~\cite{Piccinini:HowOptimalMinimumtime:2024} provide a direct comparison between an offline minimum-lap-time optimal control problem (MLT-OCP) and an online Artificial Racing Driver (ARD) that controls the very same high-fidelity vehicle model. They show that, by leveraging a physics-driven structure and a novel g-g-v performance constraint, ARD can achieve lap times within a few milliseconds of the offline benchmark and generalize to unseen circuits even under unmodeled mass variations. However, their work remains focused on quantifying the execution gap - how ARD mitigates local tracking errors - rather than on embedding disturbance handling directly into the trajectory planner.

The omission of explicit disturbance modeling at the planning stage can critically undermine constraint satisfaction: time-optimal planners typically produce trajectories that closely approach safety boundaries (e.g., collision avoidance or tire-grip limits), where even minor perturbations may lead to violations and thus severely compromise system safety.
While the use of fixed, heuristically defined safety margins around constraint sets may provide a nominal safeguard, such an approach lacks formal guarantees under uncertainty and typically leads to overly conservative and suboptimal solutions. This motivates the need for planning methods that explicitly account for uncertainty and provide quantifiable safety assurances.

In diverse fields, a variety of strategies has been proposed to tackle planning under uncertainty.                                          
In orbital mechanics, uncertainty in state estimation necessitates a probabilistic framework for modeling interactions and potential close approaches among natural and artificial celestial bodies.
A foundational reference in this context is~\cite{Tapley:StatisticalOrbitDetermination:2004}, where statistical orbit determination techniques are employed to assess and mitigate collision risks. In robotic motion planning, uncertainty-aware techniques are crucial to ensure safe navigation in environments populated with obstacles. One of the earliest contributions proposing a probabilistic representation of uncertainty is the chance-constrained framework in~\cite{Blackmore:ChanceConstrainedOptimalPath:2011}, which plans over the predicted distribution of the system state to ensure that the probability of constraint violation remains below a specified threshold. Within the Model Predictive Control paradigm, recent works have incorporated probabilistic safety guarantees. Notably, the methods presented in~\cite{Gao:CollisionfreeMotionPlanning:2023},~\cite{Zhang:RobustifiedTimeoptimalPointtopoint:2025}, and~\cite{Zhang:RobustifiedTimeoptimalCollisionfree:2024} introduce stochastic MPC frameworks for autonomous mobile platforms, where process noise is explicitly modeled and closed-loop tracking performance is maintained via either pre-computed or optimized feedback gains. The approach in~\cite{Gao:CollisionfreeMotionPlanning:2023} additionally proposes a zero-order optimization scheme to include the feedback gain directly in the optimal control problem, mitigating the growth of uncertainty over the planning horizon.
In the domain of chemical engineering, robust MPC approaches have been proposed to address uncertainty in industrial settings. For example,~\cite{Krog:SimpleFastRobust:2024} presents a heuristic method based on $n$-step-ahead uncertainty predictions, which are used to compute constraint tightening margins for the control of a polymerization reactor.

In some contexts, uncertainty arises from partial or imprecise knowledge of system parameters. This has led to a significant body of work on robust trajectory planning, particularly for unmanned aerial vehicles (UAVs), with the aim of minimizing sensitivity to state and input variations. For instance,~\cite{Brault:RobustTrajectoryPlanning:2021},~\cite{Giordano:TrajectoryGenerationMinimum:2018}, and~\cite{Brault:TubebasedTrajectoryOptimization:} propose tube-based and sensitivity-aware optimization frameworks that explicitly account for both input and closed-loop state sensitivity in the planning phase. Further developments integrate observability-aware planning into a unified multi-step optimization framework, as demonstrated in~\cite{Bohm:COPControlObservabilityaware:2022}.

Following an alternative approach, the largest Lyapunov exponent (LLE) has been proposed as an indicator of local stability~\cite{Meng:AnalysisGlobalCharacteristics:2022}, since it quantifies the average exponential rate at which infinitesimal perturbations off a fiducial trajectory grow or decay -- thus providing a direct measure of how deviations propagate through the system (negative values denote convergence toward the reference trajectory, while positive values indicate divergence)~\cite{Strogatz:NonlinearDynamicsChaos:2019}. 
%Except in chaotic systems where a positive LLE may still correspond to bounded motion on a strange attractor - a negative LLE typically signals local stability. 
Notably, for trajectories converging to a stable equilibrium, the (negative) LLE asymptotically approaches the real part of the largest eigenvalues of the linearized system at that point. This result has been leveraged in the literature to infer whether a system, not yet at equilibrium, is ultimately converging toward one, thereby enabling a localized assessment of stability based on the transient behavior~\cite{Sadri:StabilityAnalysisNonlinear:2013}. Applications of this method are particularly relevant to study chaotic vessel motions~\cite{McCue:UseLyapunovExponents:2011} and rotorcraft dynamics~\cite{Tamer:StabilityNonlinearTimeDependent:2016,Cassoni:RotorcraftStabilityAnalysis:2024}, where the primary concern is understanding the long-term evolution of the system and determining its asymptotic behavior.

%However, while Lyapunov-based indicators have been applied in vehicular contexts as well~\cite{Sadri:StabilityAnalysisNonlinear:2013,Meng:AnalysisGlobalCharacteristics:2022}, their relevance here is arguably of reduced interest - not due to their binary nature, but because even identifying asymptotic stability regions offers limited practical insight during planning. A trajectory may lie within the basin of attraction of a distant equilibrium, yet the long-term convergence may be of little operational use. What matters instead is whether, in the short term, a realistically modeled driver - acting in feedback or planning a bit into the future - can ensure that the vehicle's response to perturbations remains within safety-critical constraints, such as grip limits and collision avoidance. This perspective prioritizes short-horizon constraint-satisfying stabilizability over asymptotic notions of stability.
Although Lyapunov-based indicators have been applied in vehicular contexts as well~\cite{Sadri:StabilityAnalysisNonlinear:2013,Meng:AnalysisGlobalCharacteristics:2022}, their utility in planning is limited by the fact that asymptotic stability -- while theoretically informative -- often lacks operational relevance. A point along the planned trajectory may belong to the basin of attraction of a stable equilibrium, but if that equilibrium lies far ahead in time or outside the operational domain (e.g., off track), its practical relevance is questionable.

%A point along a planned trajectory may lie within the basin of attraction of a stable equilibrium, yet if that equilibrium is reached only asymptotically, possibly over a long horizon or outside the intended operational domain (e.g., off track), its practical utility diminishes.
In our setting, the key question is whether perturbations occurring in unstable segments of the nominal trajectory can be handled via feedback or short-horizon replanning to keep the vehicle within safety-critical limits, such as tire forces and collision boundaries. This reframes the problem: rather than long-term convergence, we evaluate whether the planned trajectory ensures short-term stabilizability under uncertainty while maintaining constraint satisfaction.



\subsection{Paper's contributions and organization}
We tackle the challenge of embedding robustness against disturbances directly into minimum-lap-time planning and propose two complementary methods. In the first one -- the open-loop worst-case covariance propagation -- at each discretization point, we propagate the state covariance forward over a fixed horizon and tighten all path constraints against the maximum covariance growth. By back-offing constraints using this \emph{worst-case} covariance, the resulting trajectory maximizes robustness without relying on feedback during planning.

In the second one -- the closed-loop covariance-aware planning, we integrate a time-varying LQR feedback policy into the planning process to realistically tame uncertainty growth. First, a nominal time-optimal trajectory is computed under deterministic dynamics. Second, an LQR controller is designed to stabilize that nominal path. Finally, we re-solve the planning problem - together with the feedback gains - so that the closed-loop covariance propagation satisfies tightened constraints via a Lyapunov-based formulation. Together, these two approaches strike a balance between computational simplicity and realistic, feedback-informed robustness, laying the groundwork for safe, high-performance lap-time planning under uncertainty.

The rest of the paper is organized as follows. 
In Section~\ref{sec:svdf} we introduce our stochastic dynamics framework, recalling the single-track vehicle model with nonlinear tires used for planning, and formulate both the continuous-time planning problem and its discrete-time counterpart via direct-collocation. Here, we also derive the probabilistic constraint back-off formulation.
 Section~\ref{sec:open_loop_planning} then outlines the open-loop worst-case covariance-propagation planning approach, while Section~\ref{sec:closed_loop_planning} presents the closed-loop, covariance-aware planner. In Section~\ref{sec:performance_comparison} we compare both methods on a representative track scenario, reporting adhesion and collision-avoidance results, parameter-sensitivity studies, and performance trade-offs. Finally, Section~\ref{sec:conclusions} draws conclusions and offers directions for future work.
  