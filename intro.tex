\section{Introduction}
\label{sec:intro}

Minimum lap time optimization is a fundamental tool in the motorsport field, enabling the synthesis of optimal trajectories and control profiles that push performance to its limits. These optimal references are widely used both offline, for vehicle setup and strategy development, and online, as feedforward inputs to advanced driver-assistance and autonomous systems.
However, despite their optimality under nominal assumptions, trajectories produced by state-of-the-art planners often lie critically close to physical and safety constraints---such as tire friction limits and collision boundaries---rendering them extremely sensitive to disturbances and modeling inaccuracies. Consequently, these ideal references may prove difficult or unsafe to follow, even for expert drivers, limiting their practical usability.

This fragility highlights a critical gap: current minimum lap time formulations rarely embed robustness explicitly.
Consequently, resulting trajectories lack reliability under uncertainties arising from mismatches between modeling assumptions and real operating conditions.
Addressing this shortcoming is essential to bridge the gap between theoretical optimality and real-world feasibility in high-performance motorsport applications.

\subsection{Related work}
In recent years, comprehensive analyses have been conducted on minimum-lap-time optimization for motorsport vehicles, covering fixed- and free-trajectory formulations~\cite{Veneri:FreetrajectoryQuasisteadystateOptimalcontrol:2020, Lovato:ThreedimensionalFixedtrajectoryApproaches:2022, Lovato:ThreedimensionalFreetrajectoryQuasisteadystate:2022}, comparing direct and indirect solution techniques~\cite{DalBianco:ComparisonDirectIndirect:2019, Bertolazzi:DirectIndirectApproach:2025}, and contrasting serial and parallel solver frameworks~\cite{Biniewicz:QuasisteadystateMinimumLap:2024, Bartali:SchwarzDecompositionParallel:2024, Bartali:ConsensusbasedAlternatingDirection:2024}.

Despite these advances, most planning frameworks still fail to incorporate robustness in the planning phase itself. A notable exception is~\cite{Timings:RobustLaptimeSimulation:2014a}, which first plans a nominal trajectory via MPC and then employs a feedback MPC to counteract disturbance realizations inferred from road-surface roughness via a ride model. An inspiring aspect is the explicit trade-off between drivability and the control effort required to stay close to the nominal path. While there are many similarities with our setting, the key differences are methodological: their approach uses a two-level, MPC-based scheme with discrete disturbance realizations in the robust layer, whereas our lap-time simulation/planning is posed as a single large-scale NLP in which robustness to (Gaussian) disturbances is embedded directly within one optimization problem.

Other contributions like Piccinini et al.~\cite{Piccinini:HowOptimalMinimumtime:2024} provide a direct comparison between an offline minimum-lap-time optimal control problem (MLT-OCP) and an online Artificial Racing Driver (ARD) that controls the very same high-fidelity vehicle model. They show that, by leveraging a physics-driven structure and a novel g-g-v performance constraint, ARD can achieve lap times within a few milliseconds of the offline benchmark and generalize to unseen circuits even under unmodeled mass variations. However, their work remains focused on quantifying the execution gap - how ARD mitigates local tracking errors - rather than on embedding disturbance handling directly into the trajectory planner.

The omission of explicit disturbance modeling at the planning stage can critically undermine constraint satisfaction: time-optimal planners typically produce trajectories that closely approach safety boundaries (e.g., collision avoidance or tire-grip limits), where even minor perturbations may lead to violations and thus severely compromise system safety.
While the use of fixed, heuristically defined safety margins around constraint sets may provide a nominal safeguard, such an approach lacks formal guarantees under uncertainty and typically leads to overly conservative and suboptimal solutions. This motivates the need for planning methods that explicitly account for uncertainty and provide quantifiable safety assurances.

In diverse fields, a variety of strategies has been proposed to tackle planning under uncertainty.
In orbital mechanics, uncertainty in state estimation necessitates a probabilistic framework for modeling interactions and potential close approaches among natural and artificial celestial bodies.
A foundational reference in this context is~\cite{Tapley:StatisticalOrbitDetermination:2004}, where statistical orbit determination techniques are employed to assess and mitigate collision risks. In robotic motion planning, uncertainty-aware techniques are crucial to ensure safe navigation in environments populated with obstacles. One of the earliest contributions proposing a probabilistic representation of uncertainty is the chance-constrained framework in~\cite{Blackmore:ChanceConstrainedOptimalPath:2011}, which plans over the predicted distribution of the system state to ensure that the probability of constraint violation remains below a specified threshold.

Within the Model Predictive Control (MPC) paradigm, recent works have incorporated probabilistic safety guarantees. Notably, the methods presented in~\cite{Gao:CollisionfreeMotionPlanning:2023},~\cite{Zhang:RobustifiedTimeoptimalPointtopoint:2025}, and~\cite{Zhang:RobustifiedTimeoptimalCollisionfree:2024} introduce stochastic MPC frameworks for autonomous mobile platforms, where process noise is explicitly modeled and closed-loop tracking performance is maintained via either pre-computed or optimized feedback gains. The approach in~\cite{Gao:CollisionfreeMotionPlanning:2023} additionally proposes a zero-order optimization scheme to include the feedback gain directly in the optimal control problem, mitigating the growth of uncertainty over the planning horizon.
In the domain of chemical engineering, robust MPC approaches have been proposed to address uncertainty in industrial settings. For example,~\cite{Krog:SimpleFastRobust:2024} presents a heuristic method based on $n$-step-ahead uncertainty predictions, which are used to compute constraint tightening margins for the control of a polymerization reactor.

In some contexts, uncertainty arises from partial or imprecise knowledge of system parameters. This has led to a significant body of work on robust trajectory planning, particularly for unmanned aerial vehicles (UAVs), with the aim of minimizing sensitivity to state and input variations. For instance,~\cite{Brault:RobustTrajectoryPlanning:2021} and~\cite{Giordano:TrajectoryGenerationMinimum:2018} propose tube-based and sensitivity-aware optimization frameworks that explicitly account for both input and closed-loop state sensitivity in the planning phase. Further developments integrate observability-aware planning into a unified multi-step optimization framework, as demonstrated in~\cite{Bohm:COPControlObservabilityaware:2022}.

Following an alternative approach, the largest Lyapunov exponent (LLE) has been proposed as an indicator of local stability~\cite{Meng:AnalysisGlobalCharacteristics:2022}. The LLE quantifies the average exponential rate at which infinitesimal perturbations off a fiducial trajectory grow or decay---thus providing a direct measure of how deviations propagate through the system.
Applications of this method are particularly relevant to study chaotic vessel motions~\cite{McCue:UseLyapunovExponents:2011} and rotorcraft dynamics~\cite{Tamer:StabilityNonlinearTimeDependent:2016,Cassoni:RotorcraftStabilityAnalysis:2024}, where the primary concern is understanding the long-term evolution of the system and determining its asymptotic behavior.
%However, while Lyapunov-based indicators have been applied in vehicular contexts as well~\cite{Sadri:StabilityAnalysisNonlinear:2013,Meng:AnalysisGlobalCharacteristics:2022}, their relevance here is arguably of reduced interest - not due to their binary nature, but because even identifying asymptotic stability regions offers limited practical insight during planning. A trajectory may lie within the basin of attraction of a distant equilibrium, yet the long-term convergence may be of little operational use. What matters instead is whether, in the short term, a realistically modeled driver - acting in feedback or planning a bit into the future - can ensure that the vehicle's response to perturbations remains within safety-critical constraints, such as grip limits and collision avoidance. This perspective prioritizes short-horizon constraint-satisfying stabilizability over asymptotic notions of stability.
Although Lyapunov-based indicators have been applied in vehicular contexts as well~\cite{Sadri:StabilityAnalysisNonlinear:2013,Meng:AnalysisGlobalCharacteristics:2022}, their utility in planning is limited by the fact that asymptotic stability -- while theoretically informative -- often lacks operational relevance. A point along the planned trajectory may belong to the basin of attraction of a stable equilibrium, but if that equilibrium lies far ahead in time or outside the operational domain (e.g., off track), its practical relevance is questionable.

%A point along a planned trajectory may lie within the basin of attraction of a stable equilibrium, yet if that equilibrium is reached only asymptotically, possibly over a long horizon or outside the intended operational domain (e.g., off track), its practical utility diminishes.
In our setting, the key question is whether perturbations occurring in unstable segments of the nominal trajectory can be handled via feedback or short-horizon replanning to keep the vehicle within safety-critical limits, such as tire forces and collision boundaries. This reframes the problem: rather than long-term convergence, we evaluate whether the planned trajectory ensures short-term stabilizability under uncertainty while maintaining constraint satisfaction.



\subsection{Paper's contributions and organization}
We tackle the challenge of embedding robustness against disturbances directly into minimum-lap-time planning and propose two complementary methods. In the first one---the open-loop \emph{horizon-based} covariance propagation---at each discretization point, we propagate the state covariance forward over a fixed horizon and tighten all path constraints against the maximum covariance growth. By back-offing constraints using this worst-case covariance, the resulting trajectory maximizes robustness without relying on feedback during planning.

In the second one -- the closed-loop covariance-aware planning, we integrate a time-varying LQR feedback policy into the planning process to realistically tame uncertainty growth. First, a nominal time-optimal trajectory is computed under deterministic dynamics. Second, an LQR controller is designed to stabilize that nominal path. Finally, we re-solve the planning problem - together with the feedback gains - so that, along this new robust trajectory, the closed-loop covariance propagation satisfies tightened constraints via a Lyapunov-based formulation. These two approaches offer a balance between computational simplicity and realistic, feedback-informed robustness, laying the groundwork for safe, high-performance lap-time planning under uncertainty in the motorsport context.

The rest of the paper is organized as follows.
In Sec.~\ref{sec:svdf} we introduce our stochastic dynamics framework, recalling the single-track vehicle model with nonlinear tires used for planning, and formulate both the continuous-time planning problem and its discrete-time counterpart via direct-collocation. Here, we also derive the probabilistic constraint back-off formulation.
Sec.~\ref{sec:open_loop_planning} then outlines the open-loop horizon-based covariance-propagation planning approach, while Sec.~\ref{sec:closed_loop_planning} presents the closed-loop, covariance-aware planner. In Sec.~\ref{sec:performance_comparison} we compare both methods on a representative track scenario, reporting parameter-sensitivity studies, analyzing the influence of different sets of constraints, and performance trade-offs.
Finally, Sec.~\ref{sec:conclusions} draws conclusions and offers directions for future work.
